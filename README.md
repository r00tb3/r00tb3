ğŸš€ Amit Vitekar â€” AI Security Engineer & Hardware/Telecom Hacker

Hi ğŸ‘‹ I'm Amit, an Offensive AI Security Engineer and Embedded/Wireless/Telecom Security Researcher who loves breaking systems across both the LLM world and the real hardware world.

I specialize in:

ğŸ”¥ LLM Red Teaming & Agent Security

ğŸ§  Adversarial Machine Learning

ğŸ›°ï¸ Telecom/5G Security & RAN/Core fuzzing

ğŸ› ï¸ Hardware, Firmware & Embedded Exploitation

ğŸ“š RAG Security, Retrieval Attacks, Poisoning Pipelines

My work typically involves jailbreak â†’ code execution â†’ exfiltration chains, agent/tool-call hijacks, RAG poisoning, secure-boot bypasses, baseband exploitation, and RF/PHY fuzzing.
I enjoy turning theoretical weaknesses into reproducible exploit chains and building security controls to prevent them.

ğŸ§¨ What I Do
ğŸ”’ Offensive AI Security

Multi-turn jailbreak design

Safety-filter evasion research

RAG attack surface mapping

Prompt/embedding poisoning

Agent misuse, tool-hijacking, memory corruption

Model extraction, dataset poisoning, backdoor reconstruction

ğŸ“¶ Telecom + Wireless + Hardware Security

LTE/5G RAN & Core protocol fuzzing

GTP/NGAP/PFCP/O-RAN fuzz harness development

SDR-based signal manipulation (USRP, BladeRF)

Firmware extraction & secure-boot bypass

Black-box hardware analysis & reverse engineering

ğŸ§ª Featured Projects
ğŸ”¥ Adversarial LLM Red Teaming Toolkit

Toolkit for multi-model jailbreak evaluation, refusal-delta testing, persona drift mapping, and automated exploit generation.

ğŸ§© Damn Vulnerable LLM & Agent Framework

A purposely insecure LLM/agent environment for testing RAG poisoning, tool-call hijacking, memory/state leakage, and embedding corruption.

ğŸ›°ï¸ 5G/RAN Fuzzing Harnesses

AFL++/LibAFL fuzz setups targeting GTP, NGAP, PFCP, O-RAN to identify RAN/Core misimplementations and memory-corruption vectors.

ğŸ› ï¸ Evil-Boot

Secure-boot bypass exploit enabling code execution on production IoT/embedded devices â€” used for vendor fixes and architecture hardening.

ğŸ§° Tech & Tools I Use Daily
ğŸ¦¾ AI Security

BITE â€¢ garak â€¢ HouYi â€¢ Rebuff â€¢ LlamaGuard â€¢ OpenAI Evals

ğŸ§± LLM Stack

LangChain â€¢ LlamaIndex â€¢ FAISS â€¢ Milvus â€¢ vLLM

ğŸ§ª Fuzzing & Exploitation

AFL++ â€¢ LibAFL â€¢ Radamsa â€¢ Scapy

ğŸ›°ï¸ Wireless / SDR

USRP â€¢ BladeRF â€¢ HackRF â€¢ GNU Radio

ğŸ Languages & Other Tools

Python â€¢ C â€¢ Bash â€¢ Docker â€¢ Linux â€¢ Kubernetes

ğŸ“ Courses & Special Training

100x Engineers GenAI Cohort â€” LLMs, Agents, Finetuning, RAG, Diffusion

HTB â€“ AI Red Teamer Path â€” LLM attack surfaces, adversarial ML, RAG exploitation

Microsoft â€“ AI Red Teaming Training Series â€” safety evaluations, misuse scenario modeling

NVIDIA â€“ Adversarial ML â€” evasion attacks (FGSM, PGD), robustness testing

ğŸ¯ What Iâ€™m Focusing on Right Now

Building more advanced LLM exploit chains

Studying agent autonomy failure modes

Combining telecom & AI security research

Contributing to open-source adversarial tools

ğŸ¤ Letâ€™s Connect

ğŸ“¬ Email: amitvitekar@ymail.com

ğŸ’¼ LinkedIn: linkedin.com/in/amitvitekar

ğŸ‰ Fun Fact

I break AI systems for a living â€” but I also break actual physical devices.
Few people do both. I like being one of them. ğŸ˜„
