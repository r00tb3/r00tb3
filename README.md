# ğŸš€ Amit Vitekar  
**AI Security Engineer â€¢ LLM Red Teamer â€¢ Hardware & Telecom Security Researcher**

Hi, I'm **Amit** â€” an Offensive AI Security Engineer and Embedded/Wireless/Telecom security researcher who enjoys breaking both **large language models** and **physical devices**.

I work across the full stack of vulnerabilities â€” from **jailbreak â†’ code execution â†’ exfiltration** in LLMs to **secure-boot bypass â†’ firmware extraction â†’ RF protocol abuse** in embedded systems.

---

## ğŸ”¥ What I Do

### ğŸ§  Offensive AI Security
- LLM jailbreaks & safety-filter evasion  
- Agent & tool-call exploitation  
- RAG poisoning, embedding corruption & retrieval hijacking  
- Adversarial ML (poisoning, backdoors, evasion)  
- Model extraction & dataset attacks  
- AI threat modeling (MITRE ATLAS, NIST AI RMF)  

### ğŸ›°ï¸ Telecom, Wireless & Hardware Security
- LTE/5G RAN & Core protocol pentest (GTP, NGAP, PFCP, O-RAN)  
- SDR-based signal manipulation (USRP, BladeRF, HackRF)  
- Firmware reverse engineering & secure-boot bypass  
- Hardware teardown, UART/JTAG/flash extraction  
- Black-box device analysis & protocol-layer exploitation  

---

## ğŸ§ª Featured Projects

### ğŸ”¥ Adversarial LLM Red Teaming Toolkit
Multi-model jailbreak generator, refusal-delta analyzer, persona-drift detection, and robustness evaluation framework.

### ğŸ› ï¸ Evil-Boot (Secure-Boot Bypass)
Firmware-level exploit enabling arbitrary code execution on embedded hardware (supported vendor remediation).

---

## ğŸ§° Tools & Technologies

### **AI Security**
`BITE` â€¢ `garak` â€¢ `HouYi` â€¢ `Rebuff` â€¢ `LlamaGuard` â€¢ `OpenAI Evals`

### **LLM & RAG Stack**
`LangChain` â€¢ `LlamaIndex` â€¢ `FAISS` â€¢ `Milvus` â€¢ `vLLM`

### **Wireless / SDR**
`USRP` â€¢ `BladeRF` â€¢ `HackRF` â€¢ `GNU Radio`

### **Languages & Platforms**
`Python` â€¢ `C` â€¢ `Bash` â€¢ `Docker` â€¢ `Linux` â€¢ `Kubernetes`

---

## ğŸ“ Courses & Specialized Training

### **100x Engineers GenAI Cohort**
- LLMs, agents, finetuning (LoRA/QLoRA), SDXL, ControlNet  
- RAG pipelines, evaluation methods, secure LLM app patterns  
- Tool-calling, MCP, multimodal agent workflows  

### **HTB Academy â€” AI Red Teamer Path**
- LLM attack surfaces, jailbreaks, misalignment attacks  
- RAG exploitation, vector poisoning, metadata injection  
- Adversarial ML, evasion, inference, backdoors  

### **Microsoft â€” AI Red Teaming Training**
- AI threat modeling, safety-policy assessment  
- Agent/tool security, misuse case analysis  
- LLM robustness, data exposure testing  

### **NVIDIA â€” Exploring Adversarial ML**
- FGSM/PGD adversarial attacks  
- Black-box & white-box model evasion  
- Robustness/transferability analysis  

---

## ğŸ¯ What Iâ€™m Working On
- Advanced agentic exploit chains  
- AI Ã— telecom cross-domain attack research  
- Better reproducible LLM adversarial evaluation frameworks  
- Open-source tools for AI red teaming  

---

## ğŸ¤ Connect With Me

ğŸ’¼ **LinkedIn:** https://www.linkedin.com/in/amitvitekar  

---

## ğŸ‰ Fun Fact
I break AI systems for a living â€” and break *actual physical devices* for fun.  
Not many people do both. ğŸ˜„
